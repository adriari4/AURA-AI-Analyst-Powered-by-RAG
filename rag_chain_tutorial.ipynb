{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal YouTube RAG Agent - Step by Step Tutorial\n",
    "\n",
    "This notebook demonstrates how to build the **ReAct Agent** used in the Value Investing Chatbot. \n",
    "I will combine **LangChain**, **OpenAI**, and **Pinecone** to create an agent that can:\n",
    "1. Answer questions based on video content (RAG).\n",
    "2. Ingest new videos on demand.\n",
    "3. Retrieve raw documents.\n",
    "4. Transcribe audio files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports\n",
    "First, we import the necessary libraries and load environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Ensure we can import from our local modules\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import AgentExecutor, create_react_agent, Tool\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain import hub\n",
    "\n",
    "# Import our custom tools\n",
    "import ingest_videos\n",
    "from backend import speech_to_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configuration\n",
    "Set up the API keys and Pinecone index name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "INDEX_NAME = \"youtube-rag-index\"\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    print(\"Error: PINECONE_API_KEY not found. Please check your .env file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Initialize Vector Store & LLM\n",
    "We use `OpenAIEmbeddings` for vectorization and `ChatOpenAI` (GPT-4o) as our reasoning engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# 2. Vector Store (Pinecone)\n",
    "vector_store = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "\n",
    "# 3. Retriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "# 4. LLM\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Define Tools\n",
    "The agent needs tools to interact with the world. We define 4 tools:\n",
    "- **RAG Answer**: Uses `RetrievalQA` to answer questions.\n",
    "- **Ingestion**: Calls `ingest_videos.process_video`.\n",
    "- **STT**: Calls `speech_to_text.transcribe_audio`.\n",
    "- **Retriever**: Fetches raw docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tool 1: RAG Answer Tool\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    ")\n",
    "\n",
    "# Tool 2: YouTube Ingestion Tool\n",
    "def ingest_video_func(url: str):\n",
    "    try:\n",
    "        ingest_videos.process_video(url, vector_store)\n",
    "        return f\"Successfully ingested video: {url}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error ingesting video: {str(e)}\"\n",
    "\n",
    "# Tool 3: Speech to Text Tool\n",
    "def speech_to_text_func(file_path: str):\n",
    "    try:\n",
    "        text = speech_to_text.transcribe_audio(file_path)\n",
    "        return text if text else \"No transcription available.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error transcribing audio: {str(e)}\"\n",
    "\n",
    "# Tool 4: Retriever Tool\n",
    "def retriever_func(query: str):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    return \"\\n\\n\".join([f\"Content: {d.page_content}\\nSource: {d.metadata.get('source', 'Unknown')}\" for d in docs])\n",
    "\n",
    "# Create Tool Objects\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"rag_answer_tool\",\n",
    "        func=qa_chain.run,\n",
    "        description=\"Use this to answer questions about value investing based on the video knowledge base. Input should be a fully formed question.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"youtube_ingestion_tool\",\n",
    "        func=ingest_video_func,\n",
    "        description=\"Use this to ingest a new YouTube video into the knowledge base. Input should be a valid YouTube URL.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"speech_to_text_tool\",\n",
    "        func=speech_to_text_func,\n",
    "        description=\"Use this to transcribe an audio file to text. Input should be a local file path.\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"retriever_tool\",\n",
    "        func=retriever_func,\n",
    "        description=\"Use this to retrieve raw documents/context from the vector store without generating an answer. Input is a search query.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create ReAct Agent\n",
    "We pull the standard ReAct prompt from LangSmith Hub and initialize the agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull Prompt\n",
    "prompt = hub.pull(\"hwchase17/react-chat\")\n",
    "\n",
    "# Create Agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "\n",
    "# Setup Memory\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "\n",
    "# Create Executor\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Run the Agent\n",
    "Now we can ask questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent_executor.invoke({\"input\": \"What is the most important rule of value investing?\"})\n",
    "print(response[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
